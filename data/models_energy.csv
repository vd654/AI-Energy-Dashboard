model,params_m,dataset,training_hours,gpu_type,kwh,co2_kg,year
ResNet-50,25,ImageNet,120,V100,250,100,2018
BERT-Base,110,BooksCorpus+Wiki,48,V100,600,260,2019
BERT-Large,340,BooksCorpus+Wiki,72,V100,1400,650,2019
T5-Small,60,C4,120,TPUv3,2200,800,2020
GPT-3 125M,125,WebText,240,V100,3200,1300,2020
T5-Base,220,C4,300,TPUv3,4200,1600,2020
ViT-B/16,86,JFT-300M,168,TPUv3,3800,1400,2021
GPT-J 6B,6000,Pile,336,A100,28000,12000,2021
CLIP ViT-B/32,151,LAION-400M,240,A100,9000,3700,2021
LLaMA-7B,7000,Mixed,720,A100,75000,30000,2022
BLOOM-176B,176000,OSCAR,4875,A100,1120000,480000,2022
Whisper-base,74,Multilingual Audio,200,A100,8000,3200,2022
LLaMA-13B,13000,Mixed,1200,A100,130000,52000,2023
Qwen-7B,7000,Mixed,800,A100,82000,33000,2023
Mistral-7B,7000,Mixed,600,A100,60000,24000,2023
Llama-3 8B,8000,Mixed,900,H100,70000,20000,2024
Phi-3 Mini,3500,Synthetic+Books,300,A100,20000,9000,2024
Qwen2 72B,72000,Mixed,1600,H100,480000,150000,2024
